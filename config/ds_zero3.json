{
  "train_batch_size": "auto",
  "train_micro_batch_size_per_gpu": "auto",
  "gradient_accumulation_steps": "auto",
  "bf16": { "enabled": "auto" },
  "zero_optimization": {
    "stage": 2,
    "overlap_comm": true,
    "contiguous_gradients": true,
    "reduce_bucket_size": 100000000,
    "allgather_bucket_size": 100000000
  },
  "scheduler": {
    "type": "WarmupDecayLR",
    "params": { "total_num_steps": "auto" }
  }
}

