   64  pip install .
   65  ls
   66  cd trl/
   67  pip install .
   68  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3
   69  ls
   70  cd personal
   71  cd krusepi
   72  cd /lustre/orion/syb111/proj-shared/Personal/krusepi/
   73  ls
   74  conda activate /lustre/orion/syb111/world-shared/environments/
   75  conda activate /lustre/orion/syb111/world-shared/environments/pytorch-rocm/
   76  pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3
   77  cd ..
   78  ls
   79  cd krusepi/
   80  ls
   81  cd p
   82  cd packages/
   83  ls
   84  cd vllm/
   85  export PYTORCH_ROCM_ARCH="gfx90a"
   86  python3 setup.py develop
   87  pip install packaging
   88  python3 setup.py develop
   89  pip install setuptools-scm
   90  python3 setup.py develop
   91  conda install --upgrade python=3.12
   92  conda install python=3.12
   93  cd ..
   94  ls
   95  cd ..
   96  cd world-shared/environments/
   97  ls
   98  rm -r pytorch-rocm/
   99  ls
  100  conda deacticate
  101  conda deactivate
  102  rm -r pytorch-rocm/
  103  conda create --prefix pytorch-rocm
  104  conda create --prefix pytorch-rocm python=3.12
  105  cd ~
  106  ls
  107  cd .cache
  108  ls
  109  cd pip
  110  ls
  111  cd ..
  112  rm -r pip
  113  rm -r conda
  114  cd /lustre/orion/syb111/world-shared/environments/
  115  ls
  116  rm -r pytorch-rocm
  117  y
  118  ls
  119  conda create --prefix pytorch-rocm python=3.12
  120  conda activate /lustre/orion/syb111/world-shared/environments/pytorch-rocm
  121  pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.3
  122  cd ..
  123  ls
  124  cd ..
  125  cd proj-shared/
  126  ks
  127  cd Personal/
  128  ls
  129  cd krusepi
  130  cd packages/
  131  ls
  132  cd vllm
  133  export PYTORCH_ROCM_ARCH="gfx90a"
  134  which gcc
  135  module load PrgEnv
  136  module load PrgEnv-gnu
  137  CC=`which gcc` CXX=`which g++` python3 setup.py develop
  138  pip install packaging
  139  pip install setuptools-scm
  140  CC=`which gcc` CXX=`which g++` python3 setup.py develop
  141  ROCM_PATH=${CRAY_ROCM_DIR} CC=`which gcc` CXX=`which g++` python3 setup.py develop
  142  module load rocm/6.3.1
  143  ROCM_PATH=${CRAY_ROCM_DIR} CC=`which gcc` CXX=`which g++` python3 setup.py develop
  144  pip install setuptools
  145  pip install ninja
  146  pip install --upgrade ninja
  147  pip install wheel
  148  pip list | grep ninja
  149  pip uninstall ninja
  150  pip list | grep ninja
  151  pip install ninja
  152  ROCM_PATH=${CRAY_ROCM_DIR} CC=`which gcc` CXX=`which g++` python3 setup.py develop
  153  ls
  154  rm -r build
  155  ROCM_PATH=${CRAY_ROCM_DIR} CC=`which gcc` CXX=`which g++` python3 setup.py develop
  156  pip install aiohttp==3.9.0b0
  157  ROCM_PATH=${CRAY_ROCM_DIR} CC=`which gcc` CXX=`which g++` python3 setup.py develop
  158  pip install --upgrade jinja2
  159  ROCM_PATH=${CRAY_ROCM_DIR} CC=`which gcc` CXX=`which g++` python3 setup.py develop
  160  pip install --upgrade opentelemetry-proto
  161  ROCM_PATH=${CRAY_ROCM_DIR} CC=`which gcc` CXX=`which g++` python3 setup.py develop
  162  pip install protobuf==4.25.7
  163  ROCM_PATH=${CRAY_ROCM_DIR} CC=`which gcc` CXX=`which g++` python3 setup.py develop
  164  cd ..
  165  ls
  166  cd trl/
  167  pip install .
  168  ls
  169  cd scripts/
  170  ls
  171  cd ..
  172  cd trl
  173  ls
  174  cd scripts/
  175  ls
  176  vim chat.py
  177  python chat.py
  178  python chat.py --model-name-or-path=/lustre/orion/syb111/proj-shared/Personal/krusepi/llms/models/Llama-4-Scout-17B-16E-Instruct
  179  ssh login12
  180  top
  181  module load rocm/6.3.1
  182  rocm-smi
  183  watch rocm-smi
  184  ls -a
  185  vim .bashrc
  186  vim .bash_profile 
  187  kruse
  188  l
  189  ls
  190  cd llms/
  191  ls
  192  vim mentor-rl/
  193  cd mentor-rl
  194  ls
  195  git branch hackathon
  196  git co hackathon 
  197  ls
  198  git st
  199  git add . 
  200  git add env.sh scripts/train_grpo_trl.py
  201  git add train_grpo_trl.slurm 
  202  git ci -m "added materials for hackathon
  203  "
  204  git push
  205  git push --set-upstream origin hackathon
  206  git push
  207  git help config
  208  cd ~
  209  ls
  210  kruse
  211  cd llms/
  212  cd mentor-rl/
  213  git st
  214  git push
  215  git push --set-upstream origin hackathon
  216  cd ~
  217  ls
  218  ls -a
  219  vim .gitconfig
  220  ls ~/.ssh/id_ed25519.pub ~/.ssh/id_rsa.pub
  221  eval "$(ssh-agent -s)"
  222  ssh-add ~/.ssh/id_ed25519
  223  cd -
  224  git remote set-url origin git@github.com:Jacobson-CompSysBio/mentor-rl.git
  225  git st
  226  git push
  227  git push --set-upstream origin hackathon
  228  git co main
  229  git merge hackathon
  230  git push
  231  source activate /lustre/orion/syb114/world-shared/environments/pytorch-rocm
  232  source activate /lustre/orion/syb111/world-shared/environments/pytorch-rocm
  233  module PrgEnv-gnu
  234  module load rocm/6.3.1
  235  kruse
  236  cd /lustre/orion/syb111/proj-shared/Personal/krusepi/
  237  cd llms/models/
  238  vllm serve --help
  239  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama4-Scout-17B-16E-Instruct --enable-expert-parallel 2
  240  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama4-Scout-17B-16E-Instruct --enable-expert-parallel=2
  241  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama4-Scout-17B-16E-Instruct --tensor-parallel-size 2
  242  export TRANSFORMERS_OFFLINE=1
  243  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama4-Scout-17B-16E-Instruct --tensor-parallel-size 2
  244  ls
  245  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 2
  246  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 4
  247  export PYTORCH_HIP_ALLOC_CONF=expandable_segments:True
  248  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 4
  249  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 6 --gpu-memory-utilization 0.95
  250  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 8 --gpu-memory-utilization 0.95
  251  kruse
  252  ls
  253  cd llms/
  254  ls
  255  cd mentor-rl
  256  ls
  257  cd ..
  258  ls
  259  cd 
  260  ls
  261  kruse
  262  ls
  263  cd packages/
  264  ls
  265  cd vllm/
  266  ls
  267  cd ..
  268  ls
  269  cd trl/
  270  ls
  271  cd trl
  272  ls
  273  cd scripts/
  274  ls
  275  cd ..
  276  cd llms/
  277  ls
  278  cd mentor-rl
  279  ls
  280  cd tests/
  281  ls
  282  vim test_vllm.py
  283  cd ..
  284  ls
  285  cd ..
  286  ls
  287  cd packages/
  288  cd vllm/
  289  ls
  290  cd vllm
  291  ls
  292  cd ..
  293  ls
  294  cd examples
  295  ls
  296  cd online_serving/
  297  ls
  298  vim openai_chat_completion_with_reasoning.py 
  299  vim multi-node-serving.sh 
  300  vim openai_chat_completion_client.py 
  301  ls
  302  cd ..
  303  ls
  304  cd ..
  305  cd llms/mentor-rl/
  306  ls
  307  cd ..
  308  source activate /lustre/orion/syb111/world-shared/environments/pytorch-rocm
  309  cd ..
  310  ls
  311  cd models/
  312  ls
  313  cd ../llms/
  314  ls
  315  cd models/
  316  ls
  317  vllm serve Llama-4-Scout-17B-16E-Instruct
  318  module load PrgEnv-gnu
  319  vllm serve Llama-4-Scout-17B-16E-Instruct
  320  LD_PRELOAD=/usr/lib64/libstdc++.so.6/ vllm serve Llama-4-Scout-17B-16E-Instruct
  321  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct
  322  module load rocm/6.3.1
  323  rocm-smi
  324  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct
  325  pip install amdsmi
  326  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct
  327  pip install amdsmi==6.3.1
  328  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct
  329  cd ..
  330  cd packages/vllm/
  331  git st
  332  git pull
  333  module load PrgEnv-gnu
  334  export PYTORCH_ROCM_ARCH="gfx90a”
  335  export PYTORCH_ROCM_ARCH="gfx90a"
  336  CC=`which gcc` CXX=`which g++` python setup.py develop
  337  git log
  338  pip list
  339  :wq
  340  pip install --upgrade setuptools
  341  CC=`which gcc` CXX=`which g++` python setup.py develop
  342  export ROCM_HOME='/opt/rocm-6.3.1'
  343  CC=`which gcc` CXX=`which g++` python setup.py develop
  344  pip list
  345  export ROCM_HOME='/opt/rocm-6.3.1'
  346  export ROCM_HOME=/opt/rocm-6.3.1
  347  CC=`which gcc` CXX=`which g++` python setup.py develop
  348  env | grep rocm
  349  env | grep ROCM_HOME
  350  python -c "import numpy"
  351  CC=`which gcc` CXX=`which g++` python setup.py develop --no-build-isolation
  352  ls
  353  pip install .
  354  pip install . --no-build-isolation
  355  cd ..
  356  cd llms/models/
  357  ls
  358  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-Instruct
  359  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct
  360  rocm-smi
  361  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct --gpu-memory-utilization=1.0
  362  ls
  363  cd ..
  364  ssh frontier04463
  365  ssh frontier09041
  366  watch rocm-smi
  367  ssh frontier09041
  368  watch rocm-smi
  369  module load rocm/6.3.1
  370  ls
  371  ls -a
  372  vim .bashrc
  373  vim .bash_profile 
  374  vim .conda
  375  cd .conda/
  376  ls
  377  cd ..
  378  ls
  379  ls -a
  380  cd miniconda3/
  381  ls
  382  ls -a
  383  cd ..
  384  ls
  385  rocm-smi
  386  watch rocm-smi
  387  cd /lustre/orion/syb111/proj-shared/Personal/krusepi/
  388  ls
  389  cd llms/
  390  ls
  391  cd mentor-rl
  392  ls
  393  cd tests
  394  ls
  395  vim test_vllm.py
  396  python test_vllm.py
  397  source activate /lustre/orion/syb111/world-shared/environments/pytorch-rocm/
  398  python test_vllm.py
  399  vim test_vllm.py 
  400  python test_vllm.py
  401  vim test_vllm.py 
  402  python test_vllm.py
  403  vim test_vllm.py 
  404  python test_vllm.py
  405  vim test_vllm.py 
  406  python test_vllm.py
  407  vim test_vllm.py 
  408  python test_vllm.py
  409  vim test_vllm.py 
  410  python test_vllm.py
  411  curl http://127.0.0.1:8000/v1
  412  curl http://127.0.0.1:8000
  413  vim test_vllm.py 
  414  curl http://localhost:8000/v1/models
  415  vim test_vllm.py 
  416  python test_vllm.py
  417  source activate /lustre/orion/syb111/world-shared/environments/pytorch-rocm/
  418  cd /lustre/orion/syb111/proj-shared/Personal/krusepi/
  419  cd llms/models/
  420  ls
  421  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 8 --dtype bfloat16
  422  export TRANSFORMERS_OFFLINE=1 
  423  export PYTORCH_HIP_ALLOC_CONF=expandable_segments:True
  424  module load PrgEnv-gnu
  425  export ROCM_HOME=/opt/rocm-6.3.1
  426  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 8 --dtype bfloat16
  427  bg 
  428  amd-smi
  429  amdsmi
  430  /opt/rocm-6.3.1/bin/amd-smi
  431  module load rocm/6.3.1
  432  /opt/rocm-6.3.1/bin/amd-smi
  433  amd-smi monitor
  434  top
  435  module load rocprofiler-systems
  436  rocm-smi
  437  LD_PRELOAD=/usr/lib64/libstdc++.so.6 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 8 --dtype bfloat16 --enable-expert-parallel
  438  `VLLM_DISABLE_COMPILE_CACHE=1 vllm serve meta-llama/Llama-4-Scout-17B-16E-Instruct \  
  439  --tensor-parallel-size 8 \ 
  440  --max-model-len 1000000 --override-generation-config='{"attn_temperature_tuning": true}'
  441  VLLM_DISABLE_COMPILE_CACHE=1 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 8--max-model-len 32000 --override-generation-config='{"attn_temperature_tuning": true}'
  442  VLLM_DISABLE_COMPILE_CACHE=1 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 8 --max-model-len 32000 --override-generation-config='{"attn_temperature_tuning": true}'
  443  LD_PRELOAD=/usr/lib64/libstdc++.so.6  VLLM_DISABLE_COMPILE_CACHE=1 vllm serve meta-llama/Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 8 --max-model-len 32000 --override-generation-config='{"attn_temperature_tuning": true}’
  444  LD_PRELOAD=/usr/lib64/libstdc++.so.6  VLLM_DISABLE_COMPILE_CACHE=1 vllm serve meta-llama/Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 8 --max-model-len 32000 --override-generation-config='{"attn_temperature_tuning": true}'
  445  LD_PRELOAD=/usr/lib64/libstdc++.so.6  VLLM_DISABLE_COMPILE_CACHE=1 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 8 --max-model-len 32000 --override-generation-config='{"attn_temperature_tuning": true}'
  446  LD_PRELOAD=/usr/lib64/libstdc++.so.6 VLLM_DISABLE_COMPILE_CACHE=1 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 8 --max-model-len 32000 --override-generation-config='{"attn_temperature_tuning": true}'
  447  salloc -A SYB114 -t 2:00:00 -q debug -p batch -N 1
  448  salloc -A SYB114 -t 2:00:00 --reservation hackathon2 -p batch -N 1
  449  salloc -A SYB114 -t 3:00:00 --reservation hackathon2 -p batch -N 1
  450  salloc -A SYB114 -t 2:00:00 --reservation hackathon2 -p batch -N 1 --exclusive
  451  kruse
  452  ls
  453  cd llms/mentor-rl/
  454  git st
  455  git add tests/test_vllm.py 
  456  git add sbcast_env.sh 
  457  git ci -m "added vllm server test"
  458  git push
  459  cd ..
  460  ls
  461  source activate /lustre/orion/syb111/world-shared/environments/pytorch-rocm
  462  module load rocm/6.3.1
  463  export TRANSFORMERS_OFFLINE=1
  464  export VLLM_CACHE_ROOT=/mnt/bb/${USER}/vllm_cache
  465  export TRITON_CACHE_DIR=/mnt/bb/${USER}/triton_cache
  466  ls
  467  cd ..
  468  ls
  469  cd models/
  470  LD_PRELOAD=/usr/lib64/libstdc++.so.6 VLLM_DISABLE_COMPILE_CACHE=1 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 4 --max-model-len 32000 --override-generation-config='{"attn_temperature_tuning": true}’
  471  LD_PRELOAD=/usr/lib64/libstdc++.so.6 VLLM_DISABLE_COMPILE_CACHE=1 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 4 --max-model-len 32000 --override-generation-config='{"attn_temperature_tuning": true}
  472  LD_PRELOAD=/usr/lib64/libstdc++.so.6 VLLM_DISABLE_COMPILE_CACHE=1 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 4 --max-model-len 32000 --override-generation-config='{"attn_temperature_tuning": true}'
  473  LD_PRELOAD=/usr/lib64/libstdc++.so.6 VLLM_DISABLE_COMPILE_CACHE=1 vllm serve Llama-4-Scout-17B-16E-Instruct --tensor-parallel-size 4 --max-model-len 16000 --override-generation-config='{"attn_temperature_tuning": true}'
  474  ls
  475  cd ..
  476  cd mentor-rl/
  477  ls
  478  vim train_grpo_trl.slurm 
  479  cp train_grpo_trl.slurm train_grpo_ddp.slurm
  480  vim train_grpo_ddp.slurm 
  481  vim train_grpo_trl.slurm 
  482  vim train_grpo_ddp.slurm 
  483  pip install ray
  484  pip install --upgrade ray
  485  ls
  486  vim train_grpo_ddp.slurm 
  487  exit
  488  ssh frontier03823
  489  rocm-smi
  490  watch rocm-smi
  491  ssh frontier
  492  rocm-smi
  493  ssh frontier00674
  494  kruse
  495  cd llms/
  496  ls
  497  cd mentor-rl/
  498  ls
  499  cd scripts/
  500  ls
  501  vim train_grpo_trl.py 
  502  ls
  503  vim train_grpo_trl.py 
  504  ls
  505  cd ..
  506  ls
  507  vim generate_data.slurm 
  508  cd scripts/
  509  ls
  510  cd ..
  511  ls
  512  vim generate_data.slurm 
  513  cd data/
  514  ls
  515  projects
  516  ls
  517  cd mentor-rl
  518  ls
  519  cd data/
  520  ls
  521  cp * /lustre/orion/syb111/proj-shared/Personal/krusepi/llms/mentor-rl/data
  522  cp * /lustre/orion/syb111/proj-shared/Personal/krusepi/llms/mentor-rl/data -r
  523  cd -
  524  cd kruse
  525  ls
  526  kruse
  527  ls
  528  cd llms/
  529  ls
  530  cd mentor-rl/
  531  ls
  532  vim data
  533  cd data/
  534  ls
  535  cd ..
  536  git st
  537  cd ..
  538  ls
  539  vim .gitignore
  540  ls
  541  rm .gitignore
  542  cd mentor-rl
  543  ls -a
  544  vim .gitignore 
  545  git st
  546  git add .
  547  git ci -m "modified grpo script for trl package"
  548  git push
  549  ls
  550  mkdir slurm
  551  mv generate_data.slurm slurm/generate_data.slurm
  552  mv train_grpo_trl.slurm slurm/train_grpo_trl.slurm
  553  ls
  554  cd slurm/
  555  ls
  556  vim train_grpo_trl.slurm 
  557  cd ..
  558  ls
  559  git add .
  560  git ci -m 
  561  git ci -m "moving slurm scripts"
  562  git push
  563  ls
  564  cd sci
  565  cd scripts/
  566  ls
  567  vim train_grpo_trl.py 
  568  vim train_grpo.py 
  569  vim train_grpo_trl.py 
  570  vim train_grpo.py 
  571  cd ..
  572  ls
  573  cd utils/
  574  ls
  575  vim dataset.py 
  576  cd ..
  577  cd scripts/
  578  ls
  579  vim train_grpo_trl.py 
  580  vim train_grpo.py 
  581  vim train_grpo_trl.py 
  582  cd ../utils/
  583  vim datasets.py
  584  vim dataset.py 
  585  cd ../scripts/
  586  ls
  587  vim train_grpo_trl.py 
  588  cd ../utils/
  589  ls
  590  vim dataset.py 
  591  cd ../scripts/
  592  ls
  593  vim train_grpo_trl.py
  594  vim train_grpo.py
  595  vim train_grpo_trl.py
  596  project
  597  projects
  598  cd mentor-rl
  599  ls
  600  cp fsdp_config.yaml /lustre/orion/syb111/proj-shared/Personal/krusepi/llms/mentor-rl/
  601  cd -
  602  kruse
  603  cd llms/mentor-rl/
  604  ls
  605  vim fsdp_config.yaml
  606  cd slurm/
  607  ls
  608  vim train_grpo_trl.slurm 
  609  cd ..
  610  ls
  611  cd slurm/
  612  cp train_grpo_trl.slurm ../
  613  ls
  614  cp generate_data.slurm ../
  615  cd ..
  616  ls
  617  rm -r slurm
  618  ls
  619  vim train_grpo_trl.slurm 
  620  cd ..
  621  ls
  622  cd ../
  623  ls
  624  cd packages/
  625  ls
  626  cd ../llms/
  627  ls
  628  cd mentor-rl/
  629  ls
  630  vim train_grpo_trl.slurm 
  631  ls
  632  cd tests/
  633  ls
  634  vim test_vllm.py 
  635  salloc -A SYB114 -J vllm_test -N 1 --reservation hackathon3 -C nvme -t 2:00:00
  636  cd ..
  637  ls
  638  vim train_grpo_ddp.slurm 
  639  sbatch train_grpo_ddp.slurm
  640  watch squeue -u krusepi
  641  tail -f
  642  tail -f slurm/3420551
  643  tail -f slurm/3420551.*
  644  ls
  645  vim env.sh
  646  vim train_grpo_ddp.slurm 
  647  vim sbcast_env.sh 
  648  sbatch train_grpo_ddp.slurm
  649  tail -f slurm/3420551.*
  650  tail -f slurm/3420560.*
  651  scancel 3420560
  652  vim train_grpo_ddp.slurm 
  653  sbatch train_grpo_ddp.slurm
  654  tail -f slurm/3420566.*
  655  ls
  656  pwd
  657  squeue -u krusepi
  658  scancel 3420566
  659  ls -la
  660  chmod -R 777
  661  chmod -R 777 .
  662  ls -la
  663  ls
  664  lx
  665  ls
  666  vim train_gpro_trl.slurm
  667  vim train_grpo_trl.slurm
  668  ls
  669  vim train_grpo_ddp.slurm 
  670  sbatch train_grpo_ddp.slurm
  671  tail -f slurm/3420814.*
  672  scancel 3420814
  673  vim train_grpo_ddp.slurm 
  674  sbatch train_grpo_ddp.slurm
  675  tail -f slurm/3420826.*
  676  scancel vllm serve: error: argument --override-generation-config: Value {attn_temperature_tuning: true} cannot be converted to <function loads at 0x7fffecec9c60>
  677  scancel 3420826
  678  vim train_grpo_ddp.slurm 
  679  sbatch train_grpo_ddp.slurm
  680  tail -f slurm/3420835.*
  681  scancel 3420835
  682  vim train_grpo_ddp.slurm 
  683  sbatch train_grpo_ddp.slurm
  684  tail -f slurm/3420845.*
  685  scancel 3420845
  686  vim train_grpo_ddp.slurm 
  687  sbatch train_grpo_ddp.slurm
  688  tail -f slurm/3420858.*
  689  less slurm/3420858.out
  690  vim train_grpo_ddp.slurm 
  691  sbatch train_grpo_ddp.slurm
  692  less slurm/3420858.out
  693  less slurm/3420873.out
  694  tail -f slurm/3420873.*
  695  scancel 3420873
  696  vim train_grpo_ddp.slurm 
  697  sbatch train_grpo_ddp.slurm
  698  tail -f slurm/3420882.*
  699  scancel 3420882
  700  vim train_grpo_ddp.slurm 
  701  sbatch train_grpo_ddp.slurm
  702  tail -f slurm/3420885.*
  703  scancel 3420885
  704  vim train_grpo_ddp.slurm 
  705  sbatch train_grpo_ddp.slurm
  706  tail -f slurm/3420924.*
  707  less slurm/3420924.out
  708  tail -f slurm/3420924.*
  709  less slurm/3420924.out
  710  vim /lustre/orion/syb111/world-shared/environments/pytorch-rocm/lib/python3.12/site-packages/vllm/worker/worker.py
  711  vim /lustre/orion/syb111/world-shared/environments/pytorch-rocm/lib/python3.12/site-packages/vllm/worker/worker_base.py
  712  vim train_grpo_ddp.slurm 
  713  sbatch train_grpo_ddp.slurm
  714  tail -f slurm/3420961.*
  715  scancel 3420961
  716  vim train_grpo_ddp.slurm 
  717  sbatch train_grpo_ddp.slurm
  718  tail -f slurm/3420966.*
  719  scancel 3420966
  720  vim train_grpo_ddp.slurm 
  721  sbatch train_grpo_ddp.slurm
  722  tail -f slurm/3420970.*
  723  vim train_grpo_ddp.slurm 
  724  scancel 3420970
  725  sbatch train_grpo_ddp.slurm
  726  tail -f slurm/3420975.*
  727  scancel 3420975
  728  vim train_grpo_ddp.slurm 
  729  sbatch train_grpo_ddp.slurm
  730  tail -f slurm/3420977.*
  731  squeue -u krusepi
  732  scancel 3420977
  733  scancel -u krusepi
  734  queue
  735  vim train_grpo_ddp.slurm 
  736  cd ..
  737  cd mentor-rl/
  738  sbatch train_grpo_ddp.slurm
  739  tail -f slurm/3420987.*
  740  scancel 3420987
  741  vim train_grpo_ddp.slurm 
  742  sbatch train_grpo_ddp.slurm
  743  tail -f slurm/3420992.*
  744  scancel 3420992
  745  vim train_grpo_ddp.slurm 
  746  sbatch train_grpo_ddp.slurm
  747  tail -f slurm/3421002.*
  748  scancel 3421002
  749  ls
  750  less slurm/3421002.err
  751  less slurm/3421002.out
  752  vim /lustre/orion/syb111/world-shared/environments/pytorch-rocm/lib/python3.12/site-packages/vllm/vllm/executor/ray_distributed_executor.py
  753  vim /lustre/orion/syb111/world-shared/environments/pytorch-rocm/lib/python3.12/site-packages/vllm/executor/ray_distributed_executor.py
  754  sbatch train_grpo_ddp.slurm
  755  tail -f slurm/3421063.*
  756  scancel 3421063
  757  vim /lustre/orion/syb111/world-shared/environments/pytorch-rocm/lib/python3.12/site-packages/vllm/worker/worker.py
  758  sbatch train_grpo_ddp.slurm
  759  tail -f slurm/3421169.*
  760  vim /lustre/orion/syb111/world-shared/environments/pytorch-rocm/lib/python3.12/site-packages/vllm/worker/worker.py
  761  sbatch train_grpo_ddp.slurm
  762  tail -f slurm/3421203.*
  763  vim /lustre/orion/syb111/world-shared/environments/pytorch-rocm/lib/python3.12/site-packages/vllm/worker/worker.py
  764  sbatch train_grpo_ddp.slurm
  765  tail -f slurm/3421278.*
  766  scancel -u krusepi
  767  vim train_grpo_ddp.slurm 
  768  sbatch train_grpo_ddp.slurm
  769  tail -f slurm/3421316.*
  770  scancel -u krusepi
  771  ls
  772  pwd 
  773  vim train_grpo_ddp.slurm 
  774  sbatch train_grpo_ddp.slurm
  775  tail -f slurm/3421388.*
  776  scancel -u krusepi
  777  vim train_grpo_ddp.slurm 
  778  sbatch train_grpo_ddp.slurm
  779  tail -f slurm/3421393.*
  780  queue
  781  scancel 3421393
  782  squeue -u krusepi
  783  ssh frontier03313
  784  kruse
  785  cd llms/mentor-rl/
  786  ls
  787  cd tests/
  788  ls
  789  vim test_vllm.py 
  790  squeue
  791  squeue -u krusepi
  792  vim test_vllm.py 
  793  python test_vllm.py
  794  source activate /lustre/orion/syb111/world-shared/environments/pytorch-rocm/
  795  python test_vllm.py
  796  vim test_vllm.py 
  797  python test_vllm.py
  798  vim test_vllm.py 
  799  python test_vllm.py
  800  ls
  801  cd ..
  802  cd ../packages/
  803  ls
  804  cd trl/
  805  git st
  806  git pull origin
  807  pip install .
  808  git pull origin main
  809  pip install .
  810  git remote add upstream https://github.com/vllm-project/vllm.git
  811  git pull origin main
  812  git pull upstream main
  813  cd ..
  814  ls
  815  rm -r trl
  816  ls
  817  git clone https://github.com/vllm-project/vllm.git
  818  git clone https://github.com/huggingface/trl.git
  819  ls
  820  cd trl
  821  pip install .
  822  git log
  823  trl
  824  cd ..
  825  trl vllm serve --help
  826  module load rocm/6.3.1
  827  trl vllm serve --help
  828  trl vllm-serve --help
  829  cd ..
  830  cd llms/
  831  ls
  832  cd mentor-rl/
  833  ls
  834  squeue -u krusepi
  835  ssh frontier
  836  ssh frontier00674
  837  source activate /lustre/orion/syb111/world-shared/environments/pytorch-rocm/
  838  pip install wandb
  839  wandb login
  840  kruse
  841  module load rocm/6.3.1
  842  cd ~
  843  ls
  844  ls -la
  845  ls -a
  846  vim .conda
  847  vim .bash_profile 
  848  vim .bashrc
  849  vim .bash_profile 
  850  source activate /lustre/orion/syb111/world-shared/environments/pytorch-rocm/
  851  krusepi
  852  kruse
  853  ls
  854  cd llms
  855  ls
  856  cd mentor-rl/
  857  ls
  858  CMD=$(tr -d "\n" << EOF
  859  export HIP_VISIBLE_DEVICES=\${ROCR_VISIBLE_DEVICES} ; 
  860  unset ROCR_VISIBLE_DEVICES ;
  861  accelerate launch
  862      --use_fsdp 
  863      --mixed_precision=no
  864      --fsdp_auto_wrap_policy=TRANSFORMER_BASED_WRAP
  865      --fsdp_sharding_strategy=FULL_SHARD
  866      --fsdp_state_dict_type=SHARDED_STATE_DICT
  867      --fsdp_activation_checkpointing=true
  868      --num_machines=${SPLIT}
  869      --num_processes=$((${SPLIT}*8))
  870      --machine_rank=\${SLURM_NODEID}
  871      --main_process_ip=${JOB_MASTER_ADDR}
  872      --main_process_port=29500
  873      --gpu_ids=0,1,2,3,4,5,6,7
  874      --dynamo_backend=no 
  875      scripts/train_grpo_trl.py &
  876  wait
  877  EOF
  878  )
  879  queue
  880  ssh frontier00384
  881  source activate /lustre/orion/syb111/world-shared/environments/pytorch-rocm/
  882  module load rocm/6.3.1
  883  CMD=$(tr -d "\n" << EOF
  884  export HIP_VISIBLE_DEVICES=\${ROCR_VISIBLE_DEVICES} ; 
  885  unset ROCR_VISIBLE_DEVICES ;
  886  accelerate launch
  887      --use_fsdp 
  888      --mixed_precision=no
  889      --fsdp_auto_wrap_policy=TRANSFORMER_BASED_WRAP
  890      --fsdp_sharding_strategy=FULL_SHARD
  891      --fsdp_state_dict_type=SHARDED_STATE_DICT
  892      --fsdp_activation_checkpointing=true
  893      --num_machines=${SPLIT}
  894      --num_processes=$((${SPLIT}*8))
  895      --machine_rank=\${SLURM_NODEID}
  896      --main_process_ip=${JOB_MASTER_ADDR}
  897      --main_process_port=29500
  898      --gpu_ids=0,1,2,3,4,5,6,7
  899      --dynamo_backend=no 
  900      scripts/train_grpo_trl.py &
  901  wait
  902  EOF
  903  )
  904  export CMD=$(tr -d "\n" << EOF
  905  export HIP_VISIBLE_DEVICES=\${ROCR_VISIBLE_DEVICES} ; 
  906  unset ROCR_VISIBLE_DEVICES ;
  907  accelerate launch
  908      --use_fsdp 
  909      --mixed_precision=no
  910      --fsdp_auto_wrap_policy=TRANSFORMER_BASED_WRAP
  911      --fsdp_sharding_strategy=FULL_SHARD
  912      --fsdp_state_dict_type=SHARDED_STATE_DICT
  913      --fsdp_activation_checkpointing=true
  914      --num_machines=${SPLIT}
  915      --num_processes=$((${SPLIT}*8))
  916      --machine_rank=\${SLURM_NODEID}
  917      --main_process_ip=${JOB_MASTER_ADDR}
  918      --main_process_port=29500
  919      --gpu_ids=0,1,2,3,4,5,6,7
  920      --dynamo_backend=no 
  921      scripts/train_grpo_trl.py &
  922  wait
  923  EOF
  924  )
  925  CMD=$(tr -d "\n" << EOF
  926  accelerate launch
  927      --use_fsdp 
  928      --mixed_precision=no
  929      --fsdp_auto_wrap_policy=TRANSFORMER_BASED_WRAP
  930      --fsdp_sharding_strategy=FULL_SHARD
  931      --fsdp_state_dict_type=SHARDED_STATE_DICT
  932      --fsdp_activation_checkpointing=true
  933      --num_machines=${SPLIT}
  934      --num_processes=$((${SPLIT}*8))
  935      --machine_rank=\${SLURM_NODEID}
  936      --main_process_ip=${JOB_MASTER_ADDR}
  937      --main_process_port=29500
  938      --gpu_ids=0,1,2,3,4,5,6,7
  939      --dynamo_backend=no 
  940      scripts/train_grpo_trl.py &
  941  wait
  942  EOF
  943  )
  944  kruse
  945  ls
  946  cd llms/
  947  ls
  948  cd ..
  949  cd models/
  950  ls
  951  cd data/
  952  ls
  953  cd json/
  954  ls
  955  cd default-b13b9b9d37e98efb/
  956  ls
  957  cd ..
  958  ls
  959  rm -r models/
  960  cd llms/
  961  cd mentor-rl/
  962  ls
  963  vim train_grpo_ddp.slurm
  964  vim train_grpo_trl.slurm 
  965  vim train_grpo_ddp.slurm
  966  cd slurm/
  967  ls
  968  cd ..
  969  ls
  970  git add .
  971  git st
  972  vim .gitignore 
  973  git add .gitignore 
  974  git ci -m "updated gitignore"
  975  vim train_grpo_ddp.slurm 
  976  rm -r slurm/
  977  ls
  978  rm core.*
  979  ls
  980  vim train_grpo_ddp.slurm 
  981  git st
  982  git push
  983  git st
  984  git add .
  985  git st
  986  git ci -m "updating all files"
  987  git push
  988  git st
  989  vim train_grpo_trl.slurm 
  990  vim train_grpo_ddp.slurm 
  991  sbatch train_grpo_ddp.slurm
  992  vim train_grpo_ddp.slurm 
  993  sbatch train_grpo_ddp.slurm
  994  squeue -u krusepi
  995  watch squeue -u krusepi
  996  squeue
  997  queue
  998  tail -f logs/3426068.*
  999  scancel -u krusepi
 1000  krusepi
 1001  ls
 1002  cd llms/
 1003  ls
 1004  cd mentor-rl/
 1005  ls
 1006  vim train_grpo_trl.slurm 
 1007  cd scripts/
 1008  ls
 1009  vim train_grpo_trl.py 
 1010  cd ../utils/
 1011  ls
 1012  vim dataset.py 
 1013  cd ..
 1014  ls
 1015  sbatch train_grpo_ddp.slurm
 1016  tail -f logs/3427959.*
 1017  scancel -u krusepi
 1018  vim train_grpo_ddp.slurm 
 1019  sbatch train_grpo_ddp.slurm
 1020  tail -f logs/3428015.*
 1021  queue
 1022  ls
 1023  vim train_grpo_trl.slurm 
 1024  vim train_grpo_ddp.slurm 
 1025  git sty
 1026  git st
 1027  git add .
 1028  git ci -m "updating slurm script"
 1029  git push
 1030  ls
 1031  rm train_grpo_trl.slurm
 1032  git st
 1033  git add .
 1034  git ci -m "removed trl slurm script; unnecessary"
 1035  git push
 1036  tail -f logs/3428015.*
 1037  ls
 1038  queue
 1039  ls
 1040  cd logs/
 1041  ls
 1042  vim 3428015.err
 1043  cd ..
 1044  ls
 1045  cd scripts/
 1046  ls
 1047  vim train_grpo_trl.py 
 1048  cd ..
 1049  scancel -u krusepi
 1050  tail -f logs/3428015.*
 1051  queue
 1052  sbatch train_grpo_ddp.slurm
 1053  vim train_grpo_ddp.slurm 
 1054  cd logs/
 1055  ls
 1056  vim 3428165.err 
 1057  cd ..
 1058  cd scripts/
 1059  ls
 1060  scancel -u krusepi
 1061  vim train_grpo_trl.py 
 1062  history
 1063  history > hackathonhistory.dat
