compute_environment: SLURM
distributed_type: MEGATRON_LM          # tells Accelerate to build TP/PP groups
num_machines: 2
num_processes: 16                      # GPUs = nodes Ã— gpus_per_node
mixed_precision: bf16
machine_rank: $SLURM_PROCID            # populated at launch
main_process_ip: $MASTER_ADDR
main_process_port: 29500

megatron_lm_tp_size: 4                 # ---- new ---- halves activations
megatron_lm_pp_size: 1                 # keep 1 if you don't want pipeline
megatron_lm_ddp_bucket_cap_mb: 25
megatron_lm_reduce_scatter: true